{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Live Events with IBM Db2 Event Store\n",
    "\n",
    "This notebook demonstrates how to interact with IBM Db2 Event Store.\n",
    "\n",
    "An external program will insert data about taxi trip duration while this notebook continuously charts updated statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Connect to IBM Db2 Event Store\n",
    "\n",
    "### 1.1 Determine the IP address of your host\n",
    "\n",
    "Obtain the IP address of the host that you want to connect to by running the appropriate command for your operating system:\n",
    "\n",
    "* On Mac, run: `ifconfig`\n",
    "* On Windows, run: `ipconfig`\n",
    "* On Linux, run: `hostname -i`\n",
    "\n",
    "On most systems, running this Python command will print the correct IP address:\n",
    "\n",
    "```\n",
    "python -c \"import socket; print(socket.gethostbyname(socket.gethostname()))\"\n",
    "```\n",
    "\n",
    "Edit the `HOST = \"XXX.XXX.XXX.XXX\"` value in the next cell to provide the IP address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set your host IP address\n",
    "HOST = \"XXX.XXX.XXX.XXX\"\n",
    "\n",
    "# Port will be 1100 for version 1.1.2 or later (5555 for version 1.1.1)\n",
    "PORT = \"1100\"\n",
    "\n",
    "# Set your Event user/pass below and for the data loader program\n",
    "EVENT_USER = \"admin\"\n",
    "EVENT_PASSWORD = \"password\"\n",
    "\n",
    "# Port that the external program will use for communication\n",
    "DAEMON_PORT = 9292"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Establishing a connection \n",
    "\n",
    "To establish a connection to IBM Db2 Event Store, you need connection endpoints. Use the configuration reader to provide a set of APIs for Event Store connection and configuration.<br/>\n",
    "\n",
    "```\n",
    "ConfigurationReader.setConnectionEndpoints(\"<HostName>:<PortNumber>\")\n",
    "```\n",
    "\n",
    "You can also specify multiple connection endpoints by providing a connection string that contains a comma-separated list of HostName:PortNumber pairs.<br/>\n",
    "```\n",
    "ConfigurationReader.setConnectionEndpoints(\"<Host1>:<Port1>,<Host2>:<Port2>,<Host3>:<Port3>\")\n",
    "```\n",
    "\n",
    "Using the configuration reader API, set up the endpoints and the user and password that will be used to connect to Event Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eventstore.oltp import EventContext\n",
    "from eventstore.oltp.row_generator import generate_tele\n",
    "from eventstore.catalog import TableSchema, IndexSpecification, SortSpecification, ColumnOrder\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from eventstore.common import ConfigurationReader\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "ConfigurationReader.setConnectionEndpoints(\"%s:%s\" % (HOST, PORT))\n",
    "ConfigurationReader.setEventUser(EVENT_USER)\n",
    "ConfigurationReader.setEventPassword(EVENT_PASSWORD)\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a database  \n",
    "Only one database can be active in Db2 Event Store. If you already have a database, you don't need to create one.<br/>\n",
    "To create a database in Event Store, you can use the `createDatabase` method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EventContext.drop_database(\"TESTDB\") # uncomment this line if you need to first drop the database\n",
    "EventContext.create_database(\"TESTDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  2.1 Open an existing database\n",
    "To use an existing database, use the following call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctx = EventContext.get_event_context(\"TESTDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create-table\"></a>\n",
    "## 3. Create your table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define a schema for the table\n",
    "To create a new table, you must first specify a schema for the table.\n",
    "Specify the columns, sharding key, and primary key, as required.<br/>\n",
    "Note that currently String is not supported as a primary key or sharding key.<br/>\n",
    "<i>The `timestamp` is not supported in the first release but still works.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eventstore.catalog import TableSchema\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "        StructField(\"id\", LongType(), nullable = False),\n",
    "        StructField(\"taxiId\", StringType(), nullable = True),\n",
    "        StructField(\"tripId\", StringType(), nullable = True),\n",
    "        StructField(\"tripStartTime\", TimestampType(), nullable = True),\n",
    "        StructField(\"tripEndTime\", TimestampType(), nullable = True),\n",
    "        StructField(\"pickupLong\", DoubleType(), nullable = True),\n",
    "        StructField(\"pickupLat\", DoubleType(), nullable = True),\n",
    "        StructField(\"dropoffLong\", DoubleType(), nullable = True),\n",
    "        StructField(\"dropoffLat\", DoubleType(), nullable = True),\n",
    "        StructField(\"tripTotal\", DoubleType(), nullable = True),\n",
    "        StructField(\"tripMiles\", DoubleType(), nullable = True),\n",
    "        StructField(\"tripSeconds\", DoubleType(), nullable = True)\n",
    "])  \n",
    "table_schema = TableSchema(\"TaxiTrips\", schema,\n",
    "                            sharding_columns=[\"id\"],\n",
    "                            pk_columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>Tip:</b> Databases in Event Store are partitioned into shards. Any Event Store node of a multi-node Event Store cluster contains 0, 1 or N shards of the defined database. In addition to the mandatory shard key, there is also the option to provide a primary key. When this key is defined, Event Store ensures that only a single version of each primary key exists in the database. In the above example, a sharding key and a primary key are defined on column id. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a id=\"create-table-two\"></a>\n",
    "### 3.2 Create the table\n",
    "Create the Event Store table based on the above, unresolved schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctx.create_table(table_schema)\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for idx, name in enumerate(table_names):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Start the insertion program\n",
    "There is a deamon program running on the host that waits for a command to start the insertion.\n",
    "<ul>\n",
    "<li>IP address: ignored in this environment</li>\n",
    "<li>rate      : records per second insertion rate</li>\n",
    "<li>db name   : name of the database used</li>\n",
    "<li>table name: name of the table</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket               # Import socket module\n",
    "\n",
    "s = socket.socket()         # Create a socket object\n",
    "\n",
    "s.connect((HOST, DAEMON_PORT))\n",
    "# <ip address>,<rate>,<db name>,<table name>\n",
    "msg = \"0.0.0.0,100,TESTDB,TaxiTrips\\n\"\n",
    "s.send(msg.encode())\n",
    "ret = s.recv(1024).decode()\n",
    "s.close\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query the table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"connect-to-es-two\"></a>\n",
    "### 4.1 Connect to  Event Store \n",
    "\n",
    "When connecting Event Store for the first time, you need to provide connection endpoints using the configuration reader.<br/>\n",
    "If you are in the same session that created the database and table, you don't need to execute this step.<br/>\n",
    "If you are in a new session, make sure you executed step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create EventSession\n",
    "\n",
    "To run a Spark SQL query, you need to establish an Event Store Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eventstore.sql import EventSession\n",
    "\n",
    "eventSession = EventSession(spark.sparkContext, \"TESTDB\")\n",
    "eventSession.open_database()\n",
    "eventSession.set_query_read_option(\"SnapshotNone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Prepare a DataFrame for the query \n",
    "The following API provides a DataFrame that holds the query results on the Event Store table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewTab = eventSession.load_event_table(\"TaxiTrips\")\n",
    "reviewTab.createOrReplaceTempView(\"TaxiTrips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Run SQL queries\n",
    "Now you can materialize the dataframe associated with the sql query by using show().  Start with a simple `count(*)` query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultSet1 = eventSession.sql(\"SELECT count(*) as totalRows FROM TaxiTrips\")\n",
    "resultSet1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query shows an aggregation. Since it is executed after the previous one you should see a larger number of total records. If you want to test for an empty dataset, use head(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultSet2 = eventSession.sql(\"\"\"\n",
    "SELECT date_format(tripStartTime, 'HH:mm') as StartTime, count(*) as count, avg(tripTotal) as AvgTotal,\n",
    "                      avg(tripMiles) as AvgMiles, \n",
    "                      avg(unix_timestamp(tripEndTime) - unix_timestamp(tripStartTime)) as AvgDuration\n",
    "FROM TaxiTrips\n",
    "GROUP BY date_format(tripStartTime, 'HH:mm')\n",
    "ORDER BY 1\n",
    "\"\"\")\n",
    "if not resultSet2.head(1):\n",
    "    print(\"Empty dataset. Is the event loader running?\")\n",
    "else:\n",
    "    resultSet2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running in a loop with a little sleep() shows that the data in the latest time slice is changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(0, 3):\n",
    "    resultSet2 = eventSession.sql(\"\"\"\n",
    "SELECT date_format(tripStartTime, 'HH:mm') as StartTime, count(*) as count, avg(tripTotal) as AvgTotal,\n",
    "                      avg(tripMiles) as AvgMiles, \n",
    "                      avg(unix_timestamp(tripEndTime) - unix_timestamp(tripStartTime)) AvgDuration\n",
    "FROM TaxiTrips\n",
    "GROUP BY date_format(tripStartTime, 'HH:mm')\n",
    "ORDER BY 1\n",
    "\"\"\")\n",
    "    resultSet2.show()\n",
    "    time.sleep(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch the latest time slice in an animated matplotlib chart to see the record count and average trip duration update as events stream in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.animation\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "colors = cm.Set3(np.linspace(0,1,48))\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "ax.set_ylabel(\"Avg Duration\")\n",
    "ax.set_xlabel(\"Start Time\")\n",
    "\n",
    "def draw_chart(fig, ax, ax2):\n",
    "    clear_output(wait=True)\n",
    "    resultSet2 = eventSession.sql(\"\"\"\n",
    "SELECT date_format(tripStartTime, 'HH:mm') as StartTime, count(*) as count, avg(tripTotal) as AvgTotal,\n",
    "                      avg(tripMiles) as AvgMiles,\n",
    "                      avg(unix_timestamp(tripEndTime) - unix_timestamp(tripStartTime)) as AvgDuration\n",
    "FROM TaxiTrips\n",
    "GROUP BY date_format(tripStartTime, 'HH:mm')\n",
    "ORDER BY 1\n",
    "\"\"\")\n",
    "    pdf = resultSet2.toPandas();\n",
    "    pdf[['StartTime', 'count']].plot(x='StartTime', y='count', kind='bar', color=colors, ax=ax, legend=None)\n",
    "    ax2.clear()\n",
    "    ax2.set_ylabel(\"Trip Count\")\n",
    "    pdf[['StartTime', 'AvgDuration']].plot(x='StartTime', y='AvgDuration', linestyle='-', marker='o', ax=ax2)\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=90);\n",
    "    display(fig)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    draw_chart(fig, ax, ax2)\n",
    "       \n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can stop the loader program with the following cell\n",
    "Otherwise, it automatically stops after 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stop the loader program\n",
    "s = socket.socket()\n",
    "s.connect((HOST, DAEMON_PORT))\n",
    "msg = \"stop\\n\"\n",
    "s.send(msg.encode())\n",
    "ret = s.recv(1024).decode()\n",
    "s.close\n",
    "print(ret)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
